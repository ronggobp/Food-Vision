{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOuI+c5cDVYlY6VTvQtLKuu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DM9sD-kBiueI"},"outputs":[],"source":["# Install tf-nightly (required until 2.13.0+ is the default in Google Colab)\n","!pip install -U -q tf-nightly\n","\n","# Check TensorFlow version (should be minimum 2.4.0+ but 2.13.0+ is better)\n","import tensorflow as tf\n","print(f\"TensorFlow version: {tf.__version__}\")\n","\n","# Add timestamp\n","import datetime\n","print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"]},{"cell_type":"code","source":["# Get helper functions file\n","import os\n","\n","if not os.path.exists(\"helper_functions.py\"):\n","    !wget https://raw.githubusercontent.com/ronggobp/tensorflow-deep-learning/main/helper_functions.py\n","else:\n","    print(\"[INFO] 'helper_functions.py' already exists, skipping download.\")"],"metadata":{"id":"OICImPZEjSIZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import series of helper functions for the notebook (we've created/used these in previous notebooks)\n","from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"],"metadata":{"id":"SpCtvl1ujScB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get TensorFlow Datasets\n","import tensorflow_datasets as tfds"],"metadata":{"id":"PcM_Bf-LjSfJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get all available datasets in TFDS\n","datasets_list = tfds.list_builders()\n","\n","# Set our target dataset and see if it exists\n","target_dataset = \"food101\"\n","print(f\"'{target_dataset}' in TensorFlow Datasets: {target_dataset in datasets_list}\")"],"metadata":{"id":"kl3T_65mjSh5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load in the data (takes about 5-6 minutes in Google Colab)\n","(train_data, test_data), ds_info = tfds.load(name=\"food101\", # target dataset to get from TFDS\n","                                             split=[\"train\", \"validation\"], # what splits of data should we get? note: not all datasets have train, valid, test\n","                                             shuffle_files=True, # shuffle files on download?\n","                                             as_supervised=True, # download data in tuple format (sample, label), e.g. (image, label)\n","                                             with_info=True) # include dataset metadata? if so, tfds.load() returns tuple (data, ds_info)"],"metadata":{"id":"HK63ePcOjSkz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Features of Food101 TFDS\n","ds_info.features"],"metadata":{"id":"LXpfEdF1jSpy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get class names\n","class_names = ds_info.features[\"label\"].names\n","class_names[:10]"],"metadata":{"id":"xuWvv5D2jSsi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Take one sample off the training data\n","train_one_sample = train_data.take(1) # samples are in format (image_tensor, label)"],"metadata":{"id":"mTdaBlN_jSvJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# What does one sample of our training data look like?\n","train_one_sample"],"metadata":{"id":"LfU9LiXLjSxz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Output info about our training sample\n","for image, label in train_one_sample:\n","  print(f\"\"\"\n","  Image shape: {image.shape}\n","  Image dtype: {image.dtype}\n","  Target class from Food101 (tensor form): {label}\n","  Class name (str form): {class_names[label.numpy()]}\n","        \"\"\")"],"metadata":{"id":"CYwcWZcajS0x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# What does an image tensor from TFDS's Food101 look like?\n","image"],"metadata":{"id":"au2imJn-jS3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# What are the min and max values?\n","tf.reduce_min(image), tf.reduce_max(image)"],"metadata":{"id":"L2jFmhAEjS9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot an image tensor\n","import matplotlib.pyplot as plt\n","plt.imshow(image)\n","plt.title(class_names[label.numpy()]) # add title to image by indexing on class_names list\n","plt.axis(False);"],"metadata":{"id":"2ZJIStxmjTAT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make a function for preprocessing images\n","def preprocess_img(image, label, img_shape=224):\n","    \"\"\"\n","    Converts image datatype from 'uint8' -> 'float32' and reshapes image to\n","    [img_shape, img_shape, color_channels]\n","    \"\"\"\n","    image = tf.image.resize(image, [img_shape, img_shape]) # reshape to img_shape\n","    return tf.cast(image, tf.float32), label # return (float32_image, label) tuple"],"metadata":{"id":"oCc1MrCYjTC7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess a single sample image and check the outputs\n","preprocessed_img = preprocess_img(image, label)[0]\n","print(f\"Image before preprocessing:\\n {image[:2]}...,\\nShape: {image.shape},\\nDatatype: {image.dtype}\\n\")\n","print(f\"Image after preprocessing:\\n {preprocessed_img[:2]}...,\\nShape: {preprocessed_img.shape},\\nDatatype: {preprocessed_img.dtype}\")"],"metadata":{"id":"KkoLIXAZjTFy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We can still plot our preprocessed image as long as we\n","# divide by 255 (for matplotlib capatibility)\n","plt.imshow(preprocessed_img/255.)\n","plt.title(class_names[label])\n","plt.axis(False);"],"metadata":{"id":"T3pv8i4mjTIq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Map preprocessing function to training data (and paralellize)\n","train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n","# Shuffle train_data and turn it into batches and prefetch it (load it faster)\n","train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n","\n","# Map prepreprocessing function to test data\n","test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n","# Turn test data into batches (don't need to shuffle)\n","test_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"0Br98KGrjTLZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data, test_data"],"metadata":{"id":"Yg1YCIdojTOL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create TensorBoard callback (already have \"create_tensorboard_callback()\" from a previous notebook)\n","from helper_functions import create_tensorboard_callback\n","\n","# Create ModelCheckpoint callback to save model's progress\n","checkpoint_path = \"model_checkpoints/cp.ckpt\" # saving weights requires \".ckpt\" extension\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n","                                                      monitor=\"val_accuracy\", # save the model weights with best validation accuracy\n","                                                      save_best_only=True, # only save the best weights\n","                                                      save_weights_only=True, # only save model weights (not whole model)\n","                                                      verbose=0) # don't print out whether or not model is being saved"],"metadata":{"id":"7eKAo5oxjTRB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Turn on mixed precision training\n","from tensorflow.keras import mixed_precision\n","mixed_precision.set_global_policy(policy=\"mixed_float16\") # set global policy to mixed precision"],"metadata":{"id":"LwrZGu46jTT6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mixed_precision.global_policy() # should output \"mixed_float16\" (if your GPU is compatible with mixed precision)"],"metadata":{"id":"MBIGUHXOjTWO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import layers\n","\n","# Create base model\n","input_shape = (224, 224, 3)\n","base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n","base_model.trainable = False # freeze base model layers\n","\n","# Create Functional model\n","inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n","# Note: EfficientNetBX models have rescaling built-in but if your model didn't you could have a layer like below\n","# x = layers.Rescaling(1./255)(x)\n","x = base_model(inputs, training=False) # set base_model to inference mode only\n","x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n","x = layers.Dense(len(class_names))(x) # want one output neuron per class\n","# Separate activation of output layer so we can output float32 activations\n","outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n","model = tf.keras.Model(inputs, outputs)\n","\n","# Compile the model\n","model.compile(loss=\"sparse_categorical_crossentropy\", # Use sparse_categorical_crossentropy when labels are *not* one-hot\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"vAhlo8UTjTZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check out our model\n","model.summary()"],"metadata":{"id":"g2M-FQdejTbc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the dtype_policy attributes of layers in our model\n","for layer in model.layers:\n","    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy) # Check the dtype policy of layers"],"metadata":{"id":"oVpguG25jTea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the layers in the base model and see what dtype policy they're using\n","for layer in model.layers[1].layers[:20]: # only check the first 20 layers to save output space\n","    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"],"metadata":{"id":"IAcy1uAWjTj6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Turn off all warnings except for errors\n","tf.get_logger().setLevel('ERROR')\n","\n","# Fit the model with callbacks\n","history_101_food_classes_feature_extract = model.fit(train_data,\n","                                                     epochs=3,\n","                                                     steps_per_epoch=len(train_data),\n","                                                     validation_data=test_data,\n","                                                     validation_steps=int(0.15 * len(test_data)),\n","                                                     callbacks=[create_tensorboard_callback(\"training_logs\",\n","                                                                                            \"efficientnetb0_101_classes_all_data_feature_extract\"),\n","                                                                model_checkpoint])"],"metadata":{"id":"tgeR5jByjTm1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate model (unsaved version) on whole test dataset\n","results_feature_extract_model = model.evaluate(test_data)\n","results_feature_extract_model"],"metadata":{"id":"mvEdLGFajTpm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. Create a function to recreate the original model\n","def create_model():\n","  # Create base model\n","  input_shape = (224, 224, 3)\n","  base_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False)\n","  base_model.trainable = False # freeze base model layers\n","\n","  # Create Functional model\n","  inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n","  # Note: EfficientNetBX models have rescaling built-in but if your model didn't you could have a layer like below\n","  # x = layers.Rescaling(1./255)(x)\n","  x = base_model(inputs, training=False) # set base_model to inference mode only\n","  x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n","  x = layers.Dense(len(class_names))(x) # want one output neuron per class\n","  # Separate activation of output layer so we can output float32 activations\n","  outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n","  model = tf.keras.Model(inputs, outputs)\n","\n","  return model\n","\n","# 2. Create and compile a new version of the original model (new weights)\n","created_model = create_model()\n","created_model.compile(loss=\"sparse_categorical_crossentropy\",\n","                      optimizer=tf.keras.optimizers.Adam(),\n","                      metrics=[\"accuracy\"])\n","\n","# 3. Load the saved weights\n","created_model.load_weights(checkpoint_path)\n","\n","# 4. Evaluate the model with loaded weights\n","results_created_model_with_loaded_weights = created_model.evaluate(test_data)"],"metadata":{"id":"KJUZHs0ijTsn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5. Loaded checkpoint weights should return very similar results to checkpoint weights prior to saving\n","import numpy as np\n","assert np.isclose(results_feature_extract_model, results_created_model_with_loaded_weights).all(), \"Loaded weights results are not close to original model.\"  # check if all elements in array are close"],"metadata":{"id":"iUO_MmBPjTvV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the layers in the base model and see what dtype policy they're using\n","for layer in created_model.layers[1].layers[:20]: # check only the first 20 layers to save printing space\n","    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"],"metadata":{"id":"n9TigKfejTya"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ## Saving model to Google Drive (optional)\n","\n","# # Create save path to drive\n","# save_dir = \"ddrive/My Drive/Colab Notebooks/07_efficientnetb0_feature_extract_model_mixed_precision/\"\n","# # os.makedirs(save_dir) # Make directory if it doesn't exist\n","\n","# # Save model\n","# model.save(save_dir)"],"metadata":{"id":"5EYrFuQgjT1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save model locally (if you're using Google Colab, your saved model will Colab instance terminates)\n","save_dir = \"07_efficientnetb0_feature_extract_model_mixed_precision\"\n","model.save(save_dir)"],"metadata":{"id":"GFM84b9zjT4S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load model previously saved above\n","loaded_saved_model = tf.keras.models.load_model(save_dir)"],"metadata":{"id":"D6N6PorpjT7N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the layers in the base model and see what dtype policy they're using\n","for layer in loaded_saved_model.layers[1].layers[:20]: # check only the first 20 layers to save output space\n","    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"],"metadata":{"id":"dWwITtUGjT-C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check loaded model performance (this should be the same as results_feature_extract_model)\n","results_loaded_saved_model = loaded_saved_model.evaluate(test_data)\n","results_loaded_saved_model"],"metadata":{"id":"a3hKqY-qjUA5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The loaded model's results should equal (or at least be very close) to the model's results prior to saving\n","# Note: this will only work if you've instatiated results variables\n","import numpy as np\n","assert np.isclose(results_feature_extract_model, results_loaded_saved_model).all()"],"metadata":{"id":"ABqJro4mjUD5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download the saved model from Google Storage\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip"],"metadata":{"id":"ErJbXEJtjUGp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Unzip the SavedModel downloaded from Google Stroage\n","!mkdir downloaded_gs_model # create new dir to store downloaded feature extraction model\n","!unzip 07_efficientnetb0_feature_extract_model_mixed_precision.zip -d downloaded_gs_model"],"metadata":{"id":"6yF90_lyjUJD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load and evaluate downloaded GS model\n","loaded_gs_model = tf.keras.models.load_model(\"downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision\")"],"metadata":{"id":"fY9oBvmnjULr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get a summary of our downloaded model\n","loaded_gs_model.summary()"],"metadata":{"id":"4CIff37EjUOW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get a summary of our downloaded model\n","loaded_gs_model.summary()"],"metadata":{"id":"z2q5Np7ojUQu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How does the loaded model perform?\n","results_loaded_gs_model = loaded_gs_model.evaluate(test_data)\n","results_loaded_gs_model"],"metadata":{"id":"6WHf-8_GjUTv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Are any of the layers in our model frozen?\n","for layer in loaded_gs_model.layers:\n","    layer.trainable = True # set all layers to trainable\n","    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy) # make sure loaded model is using mixed precision dtype_policy (\"mixed_float16\")"],"metadata":{"id":"Whkdiy9fpz_i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the layers in the base model and see what dtype policy they're using\n","for layer in loaded_gs_model.layers[1].layers[:20]:\n","    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"],"metadata":{"id":"8Kfb9UKGp0Cb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n","                                                  patience=3) # if val loss decreases for 3 epochs in a row, stop training\n","\n","# Create ModelCheckpoint callback to save best model during fine-tuning\n","checkpoint_path = \"fine_tune_checkpoints/\"\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n","                                                      save_best_only=True,\n","                                                      monitor=\"val_loss\")"],"metadata":{"id":"qd-JlGDOp0E7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating learning rate reduction callback\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n","                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n","                                                 patience=2,\n","                                                 verbose=1, # print out when learning rate goes down\n","                                                 min_lr=1e-7)"],"metadata":{"id":"gpjd34CCp0HZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","loaded_gs_model.compile(loss=\"sparse_categorical_crossentropy\", # sparse_categorical_crossentropy for labels that are *not* one-hot\n","                        optimizer=tf.keras.optimizers.Adam(0.0001), # 10x lower learning rate than the default\n","                        metrics=[\"accuracy\"])"],"metadata":{"id":"wzT6fKlSp0KL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Start to fine-tune (all layers)\n","history_101_food_classes_all_data_fine_tune = loaded_gs_model.fit(train_data,\n","                                                        epochs=100, # fine-tune for a maximum of 100 epochs\n","                                                        steps_per_epoch=len(train_data),\n","                                                        validation_data=test_data,\n","                                                        validation_steps=int(0.15 * len(test_data)), # validation during training on 15% of test data\n","                                                        callbacks=[create_tensorboard_callback(\"training_logs\", \"efficientb0_101_classes_all_data_fine_tuning\"), # track the model training logs\n","                                                                   model_checkpoint, # save only the best model during training\n","                                                                   early_stopping, # stop model after X epochs of no improvements\n","                                                                   reduce_lr]) # reduce the learning rate after X epochs of no improvements"],"metadata":{"id":"H2s6p3jWp0Ml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Save model to Google Drive (optional)\n","# loaded_gs_model.save(\"/content/drive/MyDrive/Colab Notebooks/07_efficientnetb0_fine_tuned_101_classes_mixed_precision/\")"],"metadata":{"id":"9FVRLoDOp0PM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save model locally (note: if you're using Google Colab and you save your model locally, it will be deleted when your Google Colab session ends)\n","loaded_gs_model.save(\"07_efficientnetb0_fine_tuned_101_classes_mixed_precision\")"],"metadata":{"id":"XI564QQap0RR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download and evaluate fine-tuned model from Google Storage\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_fine_tuned_101_classes_mixed_precision.zip"],"metadata":{"id":"IJPzer8bp0UE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Unzip fine-tuned model\n","!mkdir downloaded_fine_tuned_gs_model # create separate directory for fine-tuned model downloaded from Google Storage\n","!unzip 07_efficientnetb0_fine_tuned_101_classes_mixed_precision -d downloaded_fine_tuned_gs_model"],"metadata":{"id":"NtChuacPp0Wy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load in fine-tuned model from Google Storage and evaluate\n","loaded_fine_tuned_gs_model = tf.keras.models.load_model(\"downloaded_fine_tuned_gs_model/07_efficientnetb0_fine_tuned_101_classes_mixed_precision\")"],"metadata":{"id":"9kgbbVpUp0ZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get a model summary (same model architecture as above)\n","loaded_fine_tuned_gs_model.summary()"],"metadata":{"id":"-54MZd9Gp0cJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Note: Even if you're loading in the model from Google Storage, you will still need to load the test_data variable for this cell to work\n","results_downloaded_fine_tuned_gs_model = loaded_fine_tuned_gs_model.evaluate(test_data)\n","results_downloaded_fine_tuned_gs_model"],"metadata":{"id":"tAoJrHqjp0e9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Upload experiment results to TensorBoard (uncomment to run)\n","# !tensorboard dev upload --logdir ./training_logs \\\n","#   --name \"Fine-tuning EfficientNetB0 on all Food101 Data\" \\\n","#   --description \"Training results for fine-tuning EfficientNetB0 on Food101 Data with learning rate 0.0001\" \\\n","#   --one_shot"],"metadata":{"id":"IZtUeXlxp0hs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# View past TensorBoard experiments\n","# !tensorboard dev list"],"metadata":{"id":"tu351joop0ke"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Delete past TensorBoard experiments\n","# !tensorboard dev delete --experiment_id YOUR_EXPERIMENT_ID\n","\n","# Example\n","# !tensorboard dev delete --experiment_id OAE6KXizQZKQxDiqI3cnUQ"],"metadata":{"id":"bZP7Zacyp0mr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ðŸ›  Exercises\n","\n","1. Use the same evaluation techniques on the large-scale Food Vision model as you did in the previous notebook ([Transfer Learning Part 3: Scaling up](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb)). More specifically, it would be good to see:\n","  * A confusion matrix between all of the model's predictions and true labels.\n","  * A graph showing the f1-scores of each class.\n","  * A visualization of the model making predictions on various images and comparing the predictions to the ground truth.\n","    * For example, plot a sample image from the test dataset and have the title of the plot show the prediction, the prediction probability and the ground truth label.\n","2. Take 3 of your own photos of food and use the Food Vision model to make predictions on them. How does it go? Share your images/predictions with the other students.\n","3. Retrain the model (feature extraction and fine-tuning) we trained in this notebook, except this time use [`EfficientNetB4`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB4) as the base model instead of `EfficientNetB0`. Do you notice an improvement in performance? Does it take longer to train? Are there any tradeoffs to consider?\n","4. Name one important benefit of mixed precision training, how does this benefit take place?"],"metadata":{"id":"EWl6_CLsqpdK"}},{"cell_type":"code","source":[],"metadata":{"id":"leLVQt65qpmT"},"execution_count":null,"outputs":[]}]}